{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecf726ae",
   "metadata": {},
   "source": [
    "# Trabajo practico integrador: Clasificación de imágenes con PyTorch y MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca657b82",
   "metadata": {},
   "source": [
    "1. Dataset y Preprocesamiento\n",
    "¿Por qué es necesario redimensionar las imágenes a un tamaño fijo para una MLP?\n",
    "    Para poder definir las dimensiones de entrada, si las imagenes son de distinto tamaño no se puede generar un \"batch\" consistente.\n",
    "\n",
    "¿Qué ventajas ofrece Albumentations frente a otras librerías de transformación como torchvision.transforms?\n",
    "    Es más rápida, más rica en transformaciones (brillo, contraste, rotación, etc.) y es compatible con PyTorch gracias a ToTensorV2.\n",
    "\n",
    "¿Qué hace A.Normalize()? ¿Por qué es importante antes de entrenar una red?\n",
    "    Normaliza los valores de los píxeles a un rango especifico, para tener un entrenamiento estable (Se puede tener imagenes de lo mismo perocon valores de pixeles \"corridos\" y al normalizar sobrevive la caracteristica de diferencia entre pixceles). Ayuda a la convergencia de la red.\n",
    "\n",
    "¿Por qué convertimos las imágenes a ToTensorV2() al final de la pipeline?\n",
    "    Porque en esa instancia recibimos un array de NumPy (H x W x C), pero PyTorch espera tensores en formato C x H x W, por lo que debemos transformar la informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8a8a65",
   "metadata": {},
   "source": [
    "2. Arquitectura del Modelo\n",
    "¿Por qué usamos una red MLP en lugar de una CNN aquí? ¿Qué limitaciones tiene?\n",
    "    Una MLP (Perceptrón Multicapa) trata la imagen como un vector plano, pero no capta patrones espaciales (bordes, formas) por lo que tiene mas sentido utilizar una CNN. Usar una red MLP puede tener sentido si las imágenes son muy simples o quiero una base con la que comparar modelos y parametrios.\n",
    "\n",
    "¿Qué hace la capa Flatten() al principio de la red?\n",
    "    Convierte una imagen (Vector de tres dimensiones) enun vector de 1D para poder analizarlo.\n",
    "\n",
    "¿Qué función de activación se usó? ¿Por qué no usamos Sigmoid o Tanh?\n",
    "    Se usó ReLU (nn.ReLU()), porque: Evita el problema del gradiente desvanecido, acelera el entrenamiento y es más simple y eficiente. Sigmoid y Tanh son mas lentas y pueden saturar. (No son buenas con redes tan complejas)\n",
    "\n",
    "¿Qué parámetro del modelo deberíamos cambiar si aumentamos el tamaño de entrada de la imagen?\n",
    "    Deberiamos cambiar la cantidad de neuronas de entrada en la primera capa, para recibir esta nueva informacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffe78fd",
   "metadata": {},
   "source": [
    "3. Entrenamiento y Optimización\n",
    "¿Qué hace optimizer.zero_grad()?\n",
    "    Es un reseteo de los gradientes de entrenamiento, para que cada uno sea el calculo de su instancia y no se acumule con el conjunto anterior.\n",
    "\n",
    "¿Por qué usamos CrossEntropyLoss() en este caso?\n",
    "    Porque estamos entrenando una red para clasificar n multiples clases, y con esa funcion buscamos converger a scores de probabilidades de cada salida resultante.\n",
    "\n",
    "¿Cómo afecta la elección del tamaño de batch (batch_size) al entrenamiento?\n",
    "    Un batch chico implica  más generalización pero tambien más ruido, y un entrenamiento más lento. Un batch mas grande puede entrenar mas rapido y puede converger a minimos menos locales.\n",
    "\n",
    "¿Qué pasaría si no usamos model.eval() durante la validación?\n",
    "    \"model.eval()\" pone el modelo en modo evaluación, fijando algunos parametros como dropout y el batchnorm,lo que estabiliza el modelo para evaluar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bedd0d",
   "metadata": {},
   "source": [
    "4. Validación y Evaluación\n",
    "¿Qué significa una accuracy del 70% en validación pero 90% en entrenamiento?\n",
    "    Es un entrenamiento en primera instancia bueno, pero con un marcado overfitting.\n",
    "\n",
    "¿Qué otras métricas podrían ser más relevantes que accuracy en un problema real?\n",
    "    En un caso multiclase como este, analizar la matriz de confusion seria muy util para ver si esta fallando con alguna categoria especifica.\n",
    "\n",
    "¿Qué información útil nos da una matriz de confusión que no nos da la accuracy?\n",
    "    Nos muestra las todas predicciones del modelo permitiendonos ver algun error marcado (Una confusion fuerte entre dos clases).\n",
    "\n",
    "En el reporte de clasificación, ¿qué representan precision, recall y f1-score?\n",
    "    Prtesicion es el porcentaje de predicciones positivas correctas(Veo falsos positivos), recall el porcentaje de positivos detectados correctamente y F1 es un promedio ponderado de las dos anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb31132",
   "metadata": {},
   "source": [
    "5. TensorBoard y Logging\n",
    "¿Qué ventajas tiene usar TensorBoard durante el entrenamiento?\n",
    "    TensorBoard sirve para visualizar en tiempo real el proceso de entrenamiento y evaluación, pudiendo analizar perdidas, accuracys y otros valores importantes que nos permiten comparar entrenamientos y detectar rapido problemas como over y underfitting.\n",
    "\n",
    "¿Qué diferencias hay entre loguear add_scalar, add_image y add_text?\n",
    "    add_sacalar permite registrar un valor numerico, add_image una imagen (Con predicciones) y add_text un texto especifico.\n",
    "\n",
    "¿Por qué es útil guardar visualmente las imágenes de validación en TensorBoard?\n",
    "    Nos permite analizar errores sistematicos del modelo, o analizar si el conjunto de validacion elegido al azar cuenta con una tendencia inesperada que afecte el desempeño  del modelo.\n",
    "\n",
    "¿Cómo se puede comparar el desempeño de distintos experimentos en TensorBoard?\n",
    "    TensorBoard permite guardar y cargar muchas carpetas con distintas corridas y modelos y compararlos, viendo la informacion de distintos modelos al mismo tiempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c39adc",
   "metadata": {},
   "source": [
    "6. Generalización y Transferencia\n",
    "¿Qué cambios habría que hacer si quisiéramos aplicar este mismo modelo a un dataset con 100 clases?\n",
    "    En este caso debemos modificar el valor de \"num_classes\" que ya utilizamos directamente para definir la salida de la ultima capa del modelo.\n",
    "\n",
    "¿Por qué una CNN suele ser más adecuada que una MLP para clasificación de imágenes?\n",
    "    Las CNN aprovechan las propiedades espaciales de las imágenes, por lo que tienden a ser mucho mas utiles para clasificarlas.\n",
    "\n",
    "¿Qué problema podríamos tener si entrenamos este modelo con muy pocas imágenes por clase?\n",
    "    Mucho overfitting, mala generalizacion y un modelo inestable en su validacion.\n",
    "\n",
    "¿Cómo podríamos adaptar este pipeline para imágenes en escala de grises?\n",
    "    Se reduce la informacion de cada pixcel de tres canales a uno, con lo que debemos modificar la carga de imagenes en \"input_size\" a 64*64*1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "111afc38",
   "metadata": {},
   "source": [
    "7. Regularización\n",
    "Preguntas teóricas:\n",
    "¿Qué es la regularización en el contexto del entrenamiento de redes neuronales?\n",
    "    La regularización es un conjunto de técnicas para evitar el sobreajuste (overfitting) al entrenamiento. Se utiliza paraq que el modelo generalice mejor a datos que no ha visto.\n",
    "\n",
    "¿Cuál es la diferencia entre Dropout y regularización L2 (weight decay)?\n",
    "    Dropout apaga aleatoriamente neuronas durante ele entrenamiento, para que la red no dependa fuertemente de ningina neurona en especifico, mientras que L2 pealiza a los pesos muy grandes en las neuronas restandoles un termino \"perdida\".\n",
    "    \n",
    "¿Qué es BatchNorm y cómo ayuda a estabilizar el entrenamiento?\n",
    "    BatchNorm normaliza la activacion de las capas usando las medidas del batch actual (Media y varianza). Ascelera la convergencia y hace el entrenamiento menos sensibler al lr.\n",
    "\n",
    "¿Cómo se relaciona BatchNorm con la velocidad de convergencia?\n",
    "    La acelera, porque estabiliza las distribuciones internas de las capas y ayuda a que los gradientes fluyan mejor.\n",
    "\n",
    "¿Puede BatchNorm actuar como regularizador? ¿Por qué?\n",
    "    Puede, ya que introduce ruido que puede servir como regularizacion leve, pero no esta pensado para eso.\n",
    "\n",
    "¿Qué efectos visuales podrías observar en TensorBoard si hay overfitting?\n",
    "    Se ve una baja marcada en train_loss y un aumento en val_loss, y un aumento en train_acc por marcadamente por sobre val_acc.\n",
    "\n",
    "¿Cómo ayuda la regularización a mejorar la generalización del modelo?\n",
    "    La regularizacion busca que el modelo aprenda el grupo de entrenamiento \"en general\" pero que no aprenda de forma perfecta el conjunto sino que se mantengan solo los patrones mas importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb070f7",
   "metadata": {},
   "source": [
    "Preguntas prácticas: (Todas las pruebas se realizaron con 4 modelos para evitar caer en casos excepcionales)\n",
    "¿Qué efecto tuvo BatchNorm en la estabilidad y velocidad del entrenamiento?\n",
    "    El entrenamiento fue efectivamente mas veloz y mas estable(4 a 2min), se consiguio una mejora en la accuracy de Val (De aprox 50-55% sin BatchNorm a un 59-61% con BatchNorm)\n",
    "\n",
    "¿Cambió la performance de validación al combinar BatchNorm con Dropout?\n",
    "    Velocidad de corrida aumento levemente(2.5min) y el accuracy cayo ligeramente a 56%, aunque se volvio sumamente consistente entre corridas. (Mejor y mas estable para drop = 0.1 que para 0.3)\n",
    "\n",
    "¿Qué combinación de regularizadores dio mejores resultados en tus pruebas?\n",
    "    Las mejores redes fueron con BatchNorm, weight decay pero sin dropout. Aunque las corridas con dropout fueron mucho mas consistentes.\n",
    "\n",
    "¿Notaste cambios en la loss de entrenamiento al usar BatchNorm?\n",
    "    Si, una baja considerable de un 30% aproximadamente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2705e78e",
   "metadata": {},
   "source": [
    "8. Inicialización de Parámetros\n",
    "Preguntas teóricas:\n",
    "¿Por qué es importante la inicialización de los pesos en una red neuronal?\n",
    "    Una mala inicializacion puede causar un aprendizaje muy lento y convergencia a minimos locales pobres, pero una buena inicializacion evita gradientes extremos y ayuda a una mejor convergencia y mas estable.\n",
    "\n",
    "¿Qué podría ocurrir si todos los pesos se inicializan con el mismo valor?\n",
    "    Todas las neuronas podrian \"aprender el mismo parametro\" y terminar teniendo un modelo sin informacion util.\n",
    "\n",
    "¿Cuál es la diferencia entre las inicializaciones de Xavier (Glorot) y He?\n",
    "    Xavier utiliza los valores de neuronas de salida de cada capa, por lo que mantiene la varianza de las activaciones tanto de entrada como de salida, y es mas util al ser usada con sigmoid o tanh. Por otra parte He mantiene la varianza solo de la entrada, y es mas util en conjuncion con ReLU.\n",
    "\n",
    "¿Por qué en una red con ReLU suele usarse la inicialización de He?\n",
    "    ReLU deja pasar sólo valores positivos, por lo que muchos gradientes pueden volverse 0 matando neuronas. La inicialización de He mantiene la varianza de las activaciones estable, lo que evita que los gradientes desaparezcan.\n",
    "\n",
    "¿Qué capas de una red requieren inicialización explícita y cuáles no?\n",
    "    Solo las capas Linear y BatchNorm1d necesitan inicializacion, las funciones de activacion y regularizacion (ReLU o Dropout) no lo necesitan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce03be6",
   "metadata": {},
   "source": [
    "Preguntas prácticas:\n",
    "¿Qué diferencias notaste en la convergencia del modelo según la inicialización?\n",
    "    Utilizando He(ReLU) se obtuvo un entrenamiento mas rapido y con buen accuracy, aunque no mejor que el obtenido anteriormente (Aprox 59%). Utilizando Xavier(Sigmoid) el entrenamiento no se vio tan acelerado, aunque se logro un accuracy ligeramente mejor (60%). Uniform fue sumamente inestable y su velocidad vario mucho entre modelos, en accuracy llego a dar valores entre 30 y 55%.\n",
    "\n",
    "¿Alguna inicialización provocó inestabilidad (pérdida muy alta o NaNs)?\n",
    "    Uniform en muchos momentos se mantenia en valores altos de loss durante muchas epochs, estancada.\n",
    "\n",
    "¿Qué impacto tiene la inicialización sobre las métricas de validación?\n",
    "    Xavier y He mantuvieron valores altos y cercanos al maximo, aunque con uniform perdio muchisimo peso.\n",
    "\n",
    "¿Por qué bias se suele inicializar en cero?\n",
    "    El bias en cero es mas estable, ya que un corrimiento en el bias puede afectar aleatoriamente el modelo sumando flexibilidad contra estabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f11d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "47c9aae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Galo\\AppData\\Roaming\\Python\\Python310\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "import io\n",
    "import keras\n",
    "\n",
    "from helper import *\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torchvision.utils as vutils\n",
    "from keras import models, layers, optimizers, losses\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8063006",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///c:/Users/Galo/Desktop/Redes%20neuronales/mlruns/593658438528859410', creation_time=1750197235263, experiment_id='593658438528859410', last_update_time=1750197235263, lifecycle_stage='active', name='Clasificador_Tp_Integrador_CNN', tags={}>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Clasificador_Tp_Integrador_CNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d510feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "train_dir = \"data/Split_smol/train\"\n",
    "val_dir = \"data/Split_smol/val/\"\n",
    "\n",
    "# Crear directorio de logs de tensorboard\n",
    "log_dir = \"runs/experimento_skin\"\n",
    "writer = SummaryWriter(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73038b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "\n",
    "        class_names = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls: idx for idx, cls in enumerate(class_names)}\n",
    "\n",
    "        for cls in class_names:\n",
    "            cls_dir = os.path.join(root_dir, cls)\n",
    "            for fname in os.listdir(cls_dir):\n",
    "                if fname.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "                    self.image_paths.append(os.path.join(cls_dir, fname))\n",
    "                    self.labels.append(cls)\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = np.array(Image.open(self.image_paths[idx]).convert(\"RGB\"))\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented[\"image\"]\n",
    "\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9e13c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_classification_report(model, loader, writer, device, classes, step, prefix=\"val\"):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in loader:\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.numpy())\n",
    "\n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    fig_cm, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=classes)\n",
    "    disp.plot(ax=ax, cmap='Blues', xticks_rotation=45)\n",
    "    ax.set_title(f'{prefix.title()} - Confusion Matrix')\n",
    "\n",
    "    # Guardar localmente y subir a MLflow\n",
    "    fig_path = f\"confusion_matrix_{prefix}_epoch_{step}.png\"\n",
    "    fig_cm.savefig(fig_path)\n",
    "    mlflow.log_artifact(fig_path)\n",
    "    os.remove(fig_path)\n",
    "\n",
    "    plot_to_tensorboard(fig_cm, writer, f\"{prefix}/confusion_matrix\", step)\n",
    "\n",
    "    cls_report = classification_report(all_labels, all_preds, target_names=classes)\n",
    "    writer.add_text(f\"{prefix}/classification_report\", f\"<pre>{cls_report}</pre>\", step)\n",
    "\n",
    "    # También loguear texto del reporte\n",
    "    with open(f\"classification_report_{prefix}_epoch_{step}.txt\", \"w\") as f:\n",
    "        f.write(cls_report)\n",
    "    mlflow.log_artifact(f.name)\n",
    "    os.remove(f.name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0580ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funcion Entrenamiento y validación\n",
    "def evaluate(model, loader, writer, device, classes, epoch=None, prefix=\"val\"):\n",
    "    log_classification_report(model, loader, writer, device, classes, step=epoch , prefix=\"val\")\n",
    "    model.eval()\n",
    "    correct, total, loss_sum = 0, 0, 0.0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (images, labels) in enumerate(loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "\n",
    "            loss_sum += loss.item()\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            # Loguear imágenes del primer batch\n",
    "            if i == 0 and epoch is not None:\n",
    "                img_grid = vutils.make_grid(images[:8].cpu(), normalize=True)\n",
    "                writer.add_image(f\"{prefix}/images\", img_grid, global_step=epoch)\n",
    "\n",
    "    acc = 100.0 * correct / total\n",
    "    avg_loss = loss_sum / len(loader)\n",
    "\n",
    "    if epoch is not None:\n",
    "        writer.add_scalar(f\"{prefix}/loss\", avg_loss, epoch)\n",
    "        writer.add_scalar(f\"{prefix}/accuracy\", acc, epoch)\n",
    "\n",
    "    return avg_loss, acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc9cd9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):\n",
    "    def __init__(self, num_classes=2, input_size=64*64*3, dropout=0.5):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 128)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc3 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # Aplana la imagen (B, C*H*W)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf53d572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "00106b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPClassifier(nn.Module):  ### Con Batch norm\n",
    "    def __init__(self, num_classes=2, input_size=64*64*3, dropout=0.5):\n",
    "        super(MLPClassifier, self).__init__()\n",
    "        \n",
    "        self.net = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(input_size, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Dropout(dropout),\n",
    "            \n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        self.init_weights()  # Llamada a la inicialización personalizada\n",
    "\n",
    "    def init_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)  # ← Ideal para ReLU\n",
    "                init.zeros_(m.bias)             # Bias se inicializa en 0\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc7c8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "hparams_space= {\n",
    "    \"model\": (\"MLPClassifier\"),\n",
    "    \"input_size\":  [32], # 128 probar despues\n",
    "    \"batch_size\": [16],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": 200,\n",
    "    \"optimizer\":  [\"Adam\"],\n",
    "    \"HFlip\": [0.5],\n",
    "    \"VFlip\": [0.5],\n",
    "    \"SSRot\": [0.5],\n",
    "    \"RBContrast\": [0.5],\n",
    "    \"loss_fn\": \"CrossEntropyLoss\",\n",
    "    \"train_dir\": train_dir,\n",
    "    \"val_dir\": val_dir,\n",
    "    \"es_patience\": 5,\n",
    "    \"dropout\": [0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "774cb15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento y validación\n",
    "modelnbr = 0\n",
    "for input_size in hparams_space[\"input_size\"]:\n",
    "    for batch_size in hparams_space[\"batch_size\"]:\n",
    "        for lr in hparams_space[\"lr\"]:\n",
    "            for optimizer in hparams_space[\"optimizer\"]:\n",
    "                for HFlip in hparams_space[\"HFlip\"]:\n",
    "                    for VFlip in hparams_space[\"VFlip\"]:\n",
    "                        for RBContrast in hparams_space[\"RBContrast\"]:\n",
    "                            for dropout in hparams_space[\"dropout\"]:\n",
    "                                if 0.01 < 0.05:\n",
    "                                    print(f\"modelo número: {modelnbr}\", end = \"\\r\")\n",
    "                                    modelnbr += 1\n",
    "                                    hparams= {\n",
    "                                        \"model\": (\"MLPClassifier\"),\n",
    "                                        \"input_size\":  input_size,\n",
    "                                        \"batch_size\": batch_size,\n",
    "                                        \"lr\": lr,\n",
    "                                        \"epochs\": 200,\n",
    "                                        \"optimizer\": optimizer,\n",
    "                                        \"HFlip\": HFlip,\n",
    "                                        \"VFlip\": VFlip,\n",
    "                                        \"SSRot\": 0.5,\n",
    "                                        \"RBContrast\": RBContrast,\n",
    "                                        \"loss_fn\": \"CrossEntropyLoss\",\n",
    "                                        \"train_dir\": train_dir,\n",
    "                                        \"val_dir\": val_dir,\n",
    "                                        \"es_patience\": 5,\n",
    "                                        \"dropout\": dropout,\n",
    "                                    }\n",
    "                                    train_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.HorizontalFlip(p=hparams[\"HFlip\"]),\n",
    "                                        A.VerticalFlip(p=hparams[\"VFlip\"]),\n",
    "                                        A.ShiftScaleRotate(p=hparams[\"SSRot\"]),\n",
    "                                        A.RandomBrightnessContrast(p=hparams[\"RBContrast\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    val_test_transform = A.Compose([\n",
    "                                        A.Resize(hparams[\"input_size\"], hparams[\"input_size\"]),\n",
    "                                        A.Normalize(),\n",
    "                                        ToTensorV2()\n",
    "                                    ])\n",
    "                                    train_dataset = CustomImageDataset(train_dir, transform=train_transform)\n",
    "                                    val_dataset   = CustomImageDataset(val_dir, transform=val_test_transform)\n",
    "                                    batch_size = hparams[\"batch_size\"]\n",
    "                                    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "                                    val_loader   = DataLoader(val_dataset, batch_size=batch_size)\n",
    "                                    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "                                    num_classes = len(set(train_dataset.labels))\n",
    "                                    model = MLPClassifier(num_classes=num_classes, input_size = hparams[\"input_size\"]**2*3, dropout = hparams[\"dropout\"]).to(device)\n",
    "                                    criterion = nn.CrossEntropyLoss()\n",
    "                                    optimizer = optim.Adam(model.parameters(), lr=hparams[\"lr\"], weight_decay=1e-4) if hparams[\"optimizer\"]==\"Adam\" else optim.SGD(model.parameters(), lr=hparams[\"lr\"])\n",
    "                                    hparams[\"count_params\"] = count_parameters(model)\n",
    "                                    with mlflow.start_run():\n",
    "                                        # Log hiperparámetros\n",
    "                                        mlflow.log_params(hparams)\n",
    "                                        best_val_acc = 0\n",
    "                                        best_val_loss = 0\n",
    "                                        best_train_acc = 0\n",
    "                                        best_train_loss = 0\n",
    "                                        best_epoch = 0\n",
    "                                        for epoch in range(hparams[\"epochs\"]):\n",
    "                                            if epoch == 1:\n",
    "                                                for name, param in model.named_parameters():\n",
    "                                                    writer.add_histogram(name, param, epoch)\n",
    "                                            model.train()\n",
    "                                            running_loss = 0.0\n",
    "                                            correct, total = 0, 0\n",
    "                                        \n",
    "                                            for images, labels in train_loader:\n",
    "                                                images, labels = images.to(device), labels.to(device)\n",
    "                                        \n",
    "                                                optimizer.zero_grad()\n",
    "                                                outputs = model(images)\n",
    "                                                loss = criterion(outputs, labels)\n",
    "                                                loss.backward()\n",
    "                                                optimizer.step()\n",
    "                                        \n",
    "                                                running_loss += loss.item()\n",
    "                                                _, preds = torch.max(outputs, 1)\n",
    "                                                correct += (preds == labels).sum().item()\n",
    "                                                total += labels.size(0)\n",
    "                                        \n",
    "                                            train_loss = running_loss / len(train_loader)\n",
    "                                            train_acc = 100.0 * correct / total\n",
    "                                            val_loss, val_acc = evaluate(model, val_loader, writer, device,train_dataset.label_encoder.classes_,epoch=epoch, prefix=\"val\")\n",
    "                                        \n",
    "                                            print(f\"Epoch {epoch+1}:\")\n",
    "                                            print(f\"  Train Loss: {train_loss:.4f}, Accuracy: {train_acc:.2f}%\")\n",
    "                                            print(f\"  Val   Loss: {val_loss:.4f}, Accuracy: {val_acc:.2f}%\")\n",
    "                                        \n",
    "                                            writer.add_scalar(\"train/loss\", train_loss, epoch)\n",
    "                                            writer.add_scalar(\"train/accuracy\", train_acc, epoch)\n",
    "                                        \n",
    "                                            # Log en MLflow\n",
    "                                            mlflow.log_metrics({\n",
    "                                                \"train_loss\": train_loss,\n",
    "                                                \"train_accuracy\": train_acc,\n",
    "                                                \"val_loss\": val_loss,\n",
    "                                                \"val_accuracy\": val_acc\n",
    "                                            }, step=epoch)\n",
    "                                            if val_acc > best_val_acc:\n",
    "                                                best_val_acc = val_acc\n",
    "                                                best_val_loss = val_loss\n",
    "                                                best_train_acc = train_acc\n",
    "                                                best_train_loss = train_loss\n",
    "                                                best_epoch = epoch\n",
    "                                                # Guardar modelo\n",
    "                                                torch.save(model.state_dict(), \"mlp_model.pth\")\n",
    "                                                #print(\"Modelo guardado como 'mlp_model.pth'\")\n",
    "                                                mlflow.log_artifact(\"mlp_model.pth\")\n",
    "                                                mlflow.pytorch.log_model(model, artifact_path=\"pytorch_model\")\n",
    "                                            elif epoch > best_epoch + hparams[\"es_patience\"]:\n",
    "                                                #print(\"Early Stopping\")\n",
    "                                                break\n",
    "                                                \n",
    "                                        mlflow.log_metrics({\n",
    "                                                \"train_loss\": best_train_loss,\n",
    "                                                \"train_accuracy\": best_train_acc,\n",
    "                                                \"val_loss\": best_val_loss,\n",
    "                                                \"val_accuracy\": best_val_acc,\n",
    "                                                \"best_epoch\": best_epoch\n",
    "                                            }, step=epoch+1)\n",
    "                                        print(f\"\\n--- Modelo {modelnbr - 1} FINALIZADO ---\")\n",
    "                                        print(\"Hiperparámetros utilizados:\")\n",
    "                                        for k, v in hparams.items():\n",
    "                                            print(f\"  {k}: {v}\")\n",
    "                                        print(f\"Mejor época: {best_epoch}\")\n",
    "                                        print(f\"Accuracy (Train/Val): {best_train_acc:.2f}% / {best_val_acc:.2f}%\")\n",
    "                                        print(f\"Loss     (Train/Val): {best_train_loss:.4f} / {best_val_loss:.4f}\\n\")                                                \n",
    "                                        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
